
<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Yuting Yang</title>

        <meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta name="viewport" content="width=device-width, initial-scale=1">

        <link rel="stylesheet" href="css/bootstrap.min.css">
		<link rel="stylesheet" type="text/css" href="css/style.css">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>

    </head>
    <body>
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <hr>
                </div>
            </div>
            <div class="row">
                <div class="col-md-2">
                    <img class="img-responsive" src="images/me.jpg">
                </div>
                <div class="col-md-1">
                </div>
                <div class="col-md-6 text-center">
                    <h1 class="title"> Yuting Yang</h1>
                    <h3 class="header">Computer Scientist @ Adobe</h3>
                </div>
                <div class="col-md-3 text-right">
                  <h4 class="header">345 Park Avenue</h4>
                  <h4 class="header">San Jose, CA 95110</h4>
					<h4 class="header">yutyang AT adobe.com</h4>
				</div>
            </div>
            <div class="row">
                <div class="col-md-12">
                    <hr>
                </div>
            </div>
            <div class="row">
                <div class="col-md-12">
                    <h2>About me</h2>
                </div>
                <div class="col-md-12">
                  <p>I am a computer scientist at Adobe's computational photography team led by <a href="http://graphics.stanford.edu/~levoy/" target="_blank">Marc Levoy</a>. I received my Ph.D. at <a href="https://www.princeton.edu/" target="_blank">Princeton University</a> advised by <a href="https://www.cs.princeton.edu/~af/" target="_blank">Adam Finkelstein</a>. Before Princeton, I also received 3 years of Ph.D. training at the <a href="http://www.virginia.edu/" target="_blank">University of Virginia</a> advised by <a href="http://www.connellybarnes.com/" target="_blank"> Connelly Barnes</a>. </p>
                    		    <p>Please see my <a href="docs/resume.pdf">resume</a> for more information.</p>
                </div>
            </div>
            <div class="row">
                <div class="col-md-12">
                    <hr>
                </div>
            </div>
            <div class="row">
                <div class="col-md-12">
                    <h2>Research Publications <a href="https://scholar.google.com/citations?user=pOCTtlkAAAAJ&hl=en" target="_blank">(Google Scholar)</a></h2>
                    <h2></h2>
                </div>
            </div>
            <!--
            <div class="row">
                <div class="col-md-12">
                    <p>
                        <span id="explain_text">If you are not a reviewer of graphics papers, feel free to </span>
                        <a id="show_hide_a" onclick="show_func()">Show publication under review</a>
                        <span id="explain_text2">.</span>
                    </p>
                </div>
            </div>
            -->
            <div id="show_hide_div" style="display: none" -->
            </div>
            <div class="row gray">
                <div class="col-md-3">
                    <img class="img-responsive" src="images/ISMIR_2023_representative.png">
                </div>
                <div class="col-md-9">
                    <h4><b>White Box Search over Audio Synthesizer Parameters</b></h4>
                    <h4>Yuting Yang, Zeyu Jin, Connelly Barnes, Adam Finkelstein</h4>
                    <h4>ISMIR 2023</h4>
                    <p> This paper adapts and extends differentiable rendering to the problem of synthesizer parameter inference, where we search for a set of patch connections and parameters to generate audio that best matches a given target sound. We design novel gradient rules to directly differentiate the synth as a white box program to overcome the discrete nature of the synth programs. Using a simple FM synth, our method better approximates the target sound, and is preferred by AMT users when compared to baselines. </p>
<h5> [ <a href="https://pixl.cs.princeton.edu/pubs/Yang_2023_WBS/index.php" target="_blank">project page</a> ]
                </div>
            </div>
            <div class="row gray">
                <div class="col-md-3">
                    <img class="img-responsive" src="images/chain.png">
                </div>
                <div class="col-md-9">
                    <h4><b>Exploiting Program Representation with Shader Applications</b></h4>
                    <h4>Yuting Yang</h4>
                    <h4>Princeton PhD Dissertation</h4>
<h5> [ <a href="docs/dissertation.pdf" target="_blank">dissertation</a> ] [ <a href="https://docs.google.com/presentation/d/136mEc1kEk0gKs0rC4qZnq8Wu_69DY9pG/edit?usp=share_link&ouid=111963096014654836136&rtpof=true&sd=true" target="_blank">slides</a> ]
                </div>
            </div>
	    <div class="row gray">
                <div class="col-md-3">
                    <img class="img-responsive" src="docs/siggraph22_representative.png">
                </div>
                <div class="col-md-9">
                    <h4><b>Aδ: Autodiff for Discontinuous Programs - Applied to Shaders</b></h4>
                    <h4>Yuting Yang, Connelly Barnes, Andrew Adams, Adam Finkelstein</h4>
                    <h4>SIGGRAPH 2022</h4>
<p>This paper describes a compiler-based framework that extends reverse mode automatic differentiation so as to provide accurate gradients for arbitrary programs, even at discontinuities. We demonstrate the effectiveness of this framework in the context of optimizing parameters of 2D/3D procedural shader programs so that they match target illustrations.</p>
<h5>[ <a href="docs/siggraph_2022.html" target="_blank">project page</a> ] [ <a href="docs/siggraph_2022.pdf" target="_blank">paper</a> ] [ <a href="https://vimeo.com/703521232" target="_blank">video (short)</a> ] [ <a href="https://www.youtube.com/watch?v=lXXtKgkUN1o&feature=youtu.be&ab_channel=YutingYang" target="_blank">video (long)</a> ] [ <a href="https://www.youtube.com/watch?v=HvslNmNF4Ss&ab_channel=YutingYang" target="_blank">video (live demo)</a> ] [ <a href="https://github.com/yyuting/Adelta" target="_blank">Github</a> ]
                </div>
            </div>
            <div class="row gray">
                <div class="col-md-3">
                    <img class="img-responsive" src="images/program_trace.jpg">
                </div>
                <div class="col-md-9">
                    <h4><b>Learning from Shader Program Traces</b></h4>
                    <h4>Yuting Yang, Connelly Barnes, Adam Finkelstein</h4>
                    <h4>Eurographics 2022 <em style="color:#a00">(Best Paper Award)</em></h4>
<p>This paper proposes to learn from program traces of procedural fragment shaders -- programs that generate images. At each pixel, we collect the intermediate values computed at program execution, and these data form the input to the learned model. We investigate this learning task for a variety of applications: denoising, learning from partial computation, learning postprocessing filters and learning non-imagery simulations. Our method outperforms baselines both qualitatively and quantitatively. We also conduct a series of analyses that show certain features are important within the trace: these coincide with intuitively important aspects of the program. The important features can be helpful for selecting a good subset of trace features for learning, and even learning from a small subset of the trace already outperforms the baselines.</p>
<h5>[ <a href="docs/eg_2022.html" target="_blank">project page</a> ] [ <a href="docs/EG_2022.pdf" target="_blank">paper</a> ] [ <a href="https://vimeo.com/manage/videos/671765926" target="_blank">video (short)</a> ] [ <a href="https://www.youtube.com/watch?v=h56djcyD5Ik&ab_channel=YutingYang" target="_blank">video (long)</a> ] [ <a href="https://github.com/yyuting/learning_from_program_trace" target="_blank">Github</a> ]
                </div>
            </div>
            <div class="row gray">
                <div class="col-md-3">
                    <img class="img-responsive" src="images/hyperparameter.png">
                </div>
                <div class="col-md-9">
                    <h4><b>Hyperparameter Optimization in Black-box Image Processing using Differentiable Proxies</b></h4>
                    <h4>Ethan Tseng, Felix Yu, Yuting Yang, Fahim Mannan, Karl St. Arnaud, Derek Nowrouzezahrai, Jean-François Lalonde, Felix Heide</h4>
                    <h4>SIGGRAPH 2019</h4>
                    <p>We present a fully automatic system to optimize the parameters of black-box hardware and software image processing pipelines according to any arbitrary (i.e., application-specific) metric. We leverage a differentiable mapping between the configuration space and evaluation metrics, parameterized by a convolutional neural network that we train in an end-to-end fashion with imaging hardware in-the-loop. Unlike prior art, our differentiable proxies allow for high-dimension parameter search with stochastic first-order optimizers, without explicitly modeling any lower-level image processing transformations.</p>
                    <h5>[ <a href="http://www.cs.princeton.edu/~fheide/proxyopt" target="_blank">project page</a> ] [ <a href="http://www.cs.princeton.edu/~fheide/ProxyOpt.pdf" target="_blank">paper</a> ]
                </div>
            </div>
            <div class="row gray">
                <div class="col-md-3">
                    <img class="img-responsive" src="images/shader.png">
                </div>
                <div class="col-md-9">
                    <h4><b>Approximate Program Smoothing Using Mean-Variance Statistics, with Application to Procedural Shader Bandlimiting</b></h4>
                    <h4>Yuting Yang, Connelly Barnes</h4>
                    <h4>Eurographics 2018</h4>
                    <p>This paper introduces a general method to approximate the convolution of an arbitrary program with a Gaussian kernel which facilitates smoothing the program. We give several approximations including a novel adaptive Gaussian approximation that is accurate up to the second order in the standard deviation of the smoothing kernel. We construct a compiler framework that automatically chooses approximations for different parts of the program. We then apply this framework to bandlimit procedural shaders.</p>
                    <h5>[ <a href="docs/eg_2018.html" target="_blank">project page</a> ] [ <a href="docs/EG_2018_final.pdf" target="_blank">paper</a> ] [ <a href="docs/EG_2018_final_supplemental.pdf" target="_blank">supplemental</a> ] [ <a href="https://vimeo.com/261015455" target="_blank">video (Vimeo)</a> ]
                </div>
            </div>
            <div class="row gray">
                <div class="col-md-3">
                    <img class="img-responsive" src="images/vizgen.jpg">
                </div>
                <div class="col-md-9">
                    <h4><b>VizGen: Accelerating Visual Computing Prototypes in Dynamic Languages</b></h4>
                    <h4>Yuting Yang, Sam Prestwood, Connelly Barnes</h4>
                    <h4>SIGGRAPH Asia 2016</h4>
                    <p>This paper introduces a novel domain-specific compiler, which translates visual computing programs written in dynamic languages to highly efficient code. We define "dynamic" languages as those such as Python and MATLAB, which feature dynamic typing and can be useful for rapid prototyping, but introduces significant overheads in program execution time. We introduce a compiler framework for accelerating visual computing programs written in general-purpose dynamic languages. Our compiler allows frequently orders of magnitude performance gains over general compilers for dynamic languages by specializing the compiler for visual computation.</p>
		    <h5>[ <a href="docs/sig_asia_2016.html" target="_blank">project page</a> ] [ <a href="docs/VizGen.pdf" target="_blank">paper</a> ] [ <a href="docs/VizGen_supplemental.pdf" target="_blank">supplemental</a> ]  [ <a href="https://docs.google.com/presentation/d/1_rFrvUbYDK4UPpjFgMwADCJsxERdzvtP/edit?usp=sharing&ouid=111963096014654836136&rtpof=true&sd=true" target="_blank">slides (pptx)</a> ]
                </div>
            </div>
            <div class="row gray">
                <div class="col-md-3">
                    <img class="img-responsive" src="images/vehicle_tracking.jpg">
                </div>
                <div class="col-md-9">
                    <h4><b>Intersection monitoring from video using 3D reconstruction</b></h4>
                    <h4>Yuting Yang, Camillo Taylor, Daniel Lee</h4>
                    <h4>ITS International January February 2016</h4>
                    <p>Traffic information can be collected from existing inexpensive roadside cameras but extracting it often entails manual work or costly commercial software. We proposed a method that tracks and counts vehicles in the video and to use the tracking information to compute a 3D model for the vehicles and visualise the 2D road situation into 3D. The 3D model can provide feedback on the tracking and counting model for future research. </p>
                    <h5>[ <a href="http://www.itsinternational.com/categories/detection-monitoring-machine-vision/features/intersection-monitoring-from-video-using-3d-reconstruction/" target="_blank">article</a> ]
                </div>
            </div>
            <div class="row">
                <div class="col-md-12">
                    <hr>
                </div>
            </div>
            <div class="row">
                <div class="col-md-12">
                    <h2>Academics</h2>
                </div>
            </div>
            <div class="row">
                <div class="col-md-12">
                    <h4><b>M.S., Electrical Engineering</b></h4>
                    <p>I received my master degree at the <a href="http://www.upenn.edu" target="_blank">University of Pennsylvania</a> in May 2015. My thesis was "Road Intersecting Monitoring from Video with 3D Reconstruction", advised by <a href="https://www.seas.upenn.edu/~ddlee/" target="_blank">Dr. Daniel Lee</a> and <a href="https://www.cis.upenn.edu/~cjtaylor/home.html" target="_blank">Dr. Camillo Taylor</a>.
                </div>
            </div>
            <div class="row">
                <div class="col-md-12">
                    <h4><b>B.S., Electronics and Information Engineering</b></h4>
                    <p>I received my bachelor degree at <a href="http://english.hust.edu.cn" target="_blank">Huazhong University of Science and Technology</a> in June 2013. My thesis was "Motion Detection from Video Surveillance", advised by Dr. Hao Wen.
                </div>
            </div>
            <div class="row">
                <div class="col-md-12">
                    <hr>
                </div>
            </div>
            <div class="row">
                <div class="col-md-12 text-right">
                    <font color="grey" size="-1">
                        Theme uses <a href="http://getbootstrap.com/" target="_blank">Bootstrap</a>. Inspired by <a href="http://www.cs.virginia.edu/~ft3ex/" target="_blank">Fuwen Tan's homepage</a>.
                    </font>
                </div>
            </div>
            <div class="row">
                <div class="col-md-12">
                    <hr>
                </div>
            </div>
        </div>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-90918037-3"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'UA-90918037-3');
        </script>

        <script type="text/javascript" src="domcollapse.js"></script>
        <script type="text/javascript">
            function show_hide() {
                var x = document.getElementById('show_hide_div');
                if (x.style.display === 'none') {
                    x.style.display = 'block';
                    //alert('showing');
                } else {
                    x.style.display = 'none';
                    //alert('hiding');
                }
                document.getElementById('explain_text').style.display = 'none';
                document.getElementById('explain_text2').style.display = 'none';
            }
            function show_func() {
                //alert('show_func');
                //alert(document.getElementById('show_hide_a').outerHTML);
                document.getElementById('show_hide_a').outerHTML = "<a id='show_hide_a' href='javascript:hide_func()'>Hide publications under review.</a>";
                show_hide();
            }
            function hide_func() {
                //alert('hide_func');
                //alert(document.getElementById('show_hide_a').outerHTML);
                document.getElementById('show_hide_a').outerHTML = "<a id='show_hide_a' href='javascript:show_func()'>Show publications under review.</a>";
                show_hide();
            }
        </script>
    </body>
</html>
